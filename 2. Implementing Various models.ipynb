{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Automatic Soil Testing Using AI </h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NO3   NH4    P   K  SO4     B  Organic Matter   pH   Zn   Cu  Fe   Ca  \\\n",
      "0  23.00  2.25  101  32   12  0.71            0.96  7.8  1.7  0.3   4  6.6   \n",
      "1   6.00  0.75   58  10    7  0.27            0.30  8.2  0.8  0.1   1  5.0   \n",
      "2   7.25  1.00  115   8   10  0.56            0.62  7.9  1.4  0.2   2  5.2   \n",
      "3  21.00  1.25  130  30   13  0.78            1.04  7.9  1.8  0.3   2  6.1   \n",
      "4   1.75  0.50   17   4    6  0.25            0.10  8.8  0.3  0.1   1  4.7   \n",
      "5   2.00  0.75   40   8    6  0.24            0.22  8.3  0.9  0.1   1  4.9   \n",
      "6   1.50  0.25   21  12    5  0.20            0.08  8.7  0.3  0.1   1  5.7   \n",
      "7  14.75  0.75   53  12    8  0.18            0.41  8.3  0.8  0.1   1  5.6   \n",
      "8  12.75  2.00   72  15   10  0.64            0.45  8.0  1.2  0.2   2  5.6   \n",
      "9  18.50  1.75   47  21    7  0.29            0.28  8.3  0.6  0.1   1  5.9   \n",
      "\n",
      "    Mg    Na  \n",
      "0  0.8  0.12  \n",
      "1  0.5  0.07  \n",
      "2  0.4  0.04  \n",
      "3  0.7  0.10  \n",
      "4  0.5  0.10  \n",
      "5  0.5  0.09  \n",
      "6  0.4  0.08  \n",
      "7  0.4  0.07  \n",
      "8  0.5  0.08  \n",
      "9  0.5  0.11  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_rows',200)\n",
    "\n",
    "\n",
    "data = pd.read_csv('processed_soil_data.csv')\n",
    "\n",
    "\n",
    "X, Y = data[data.columns[1:]], data['Vegetation Cover']\n",
    "\n",
    "\n",
    "print(X[:10])\n",
    "# Normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X, Y = scaler.fit_transform(X.values), scaler.fit_transform(Y.values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions to implement a general model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def train(model, X, Y):\n",
    "    model.fit(X,Y)\n",
    "    return model\n",
    "\n",
    "def print_metrics(model, X, Y):\n",
    "    \n",
    "    # predicted test data\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Mean square Error\n",
    "    mean_square_error = np.sum((y_pred-Y)**2)/len(y_pred)\n",
    "    print('Mean Square Error : ', mean_square_error)\n",
    "    \n",
    "    # Root Mean Square Error\n",
    "    print('Root Mean Square Error : ', mean_square_error**0.5)\n",
    "    \n",
    "    # Mean absolute Error\n",
    "    print('Mean Absolute Error : ', np.abs(Y - y_pred).sum()/len(y_pred))\n",
    "    \n",
    "    # R2 Error\n",
    "    print('R2 Score : ', r2_score(Y, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.10, random_state=43)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error :  0.1080737308531992\n",
      "Root Mean Square Error :  0.3287456932846409\n",
      "Mean Absolute Error :  0.30683537447564435\n",
      "R2 Score :  0.119984517017235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "linearModel = LinearRegression()\n",
    "\n",
    "# training\n",
    "linearModel = train(linearModel,X_train,Y_train)\n",
    "\n",
    "#print metrics\n",
    "print_metrics(linearModel, X_test, Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(linearModel, open('Models/Linear Model', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Lasso and Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "Mean Square Error :  1.309367160894724\n",
      "Root Mean Square Error :  1.1442758237832014\n",
      "Mean Absolute Error :  3.3318239869964\n",
      "R2 Score :  -0.06618265641417254\n",
      "\n",
      "\n",
      "Ridge\n",
      "Mean Square Error :  0.10308474975935131\n",
      "Root Mean Square Error :  0.3210681388106757\n",
      "Mean Absolute Error :  0.2941749944200712\n",
      "R2 Score :  0.16060845562131687\n"
     ]
    }
   ],
   "source": [
    "#Lasso\n",
    "lasso = Lasso(alpha=0.6)\n",
    "\n",
    "#training \n",
    "lasso = train(lasso,X_train,Y_train)\n",
    "\n",
    "#print metrics\n",
    "print('Lasso')\n",
    "print_metrics(lasso, X_test, Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(Lasso, open('Models/Lasso', 'wb'))\n",
    "\n",
    "print('\\n')\n",
    "#Ridge\n",
    "ridge = Ridge(alpha=1)\n",
    "\n",
    "#training\n",
    "ridge = train(ridge,X_train,Y_train)\n",
    "\n",
    "#print_metrics\n",
    "print('Ridge')\n",
    "print_metrics(ridge,X_test,Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(ridge, open('Models/Ridge', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, Ridge seems to work better than Lasso and Simple linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel : Linear\n",
      "Mean Square Error :  1.3703070747399122\n",
      "Root Mean Square Error :  1.170601159550046\n",
      "Mean Absolute Error :  3.2688004338889898\n",
      "R2 Score :  0.317595250440739\n",
      "\n",
      "\n",
      "Kernel : RBF\n",
      "Mean Square Error :  2.265151800673897\n",
      "Root Mean Square Error :  1.5050421258801685\n",
      "Mean Absolute Error :  4.046706519001624\n",
      "R2 Score :  -0.1549667925623004\n",
      "\n",
      "\n",
      "Kernel : Poly\n",
      "Mean Square Error :  1.3757893146053637\n",
      "Root Mean Square Error :  1.1729404565472894\n",
      "Mean Absolute Error :  3.211327987361842\n",
      "R2 Score :  0.25895631954388965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Vikash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Vikash\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Vikash\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# linear Model\n",
    "svr_linear = SVR(kernel='linear', C=200, epsilon=0.3)\n",
    "\n",
    "# RBF kernel\n",
    "svr_rbf = SVR(kernel='rbf', C=10, gamma=0.2)\n",
    "\n",
    "# non-linear model\n",
    "svr_poly = SVR(kernel='poly', degree=2, C=650, epsilon=0.3)\n",
    "\n",
    "\n",
    "print('Kernel : Linear')\n",
    "svr_linear = train(svr_linear,X_train,Y_train)\n",
    "print_metrics(svr_linear, X_test, Y_test)\n",
    "\n",
    "print('\\n')\n",
    "print('Kernel : RBF')\n",
    "svr_rbf = train(svr_rbf,X_train,Y_train)\n",
    "print_metrics(svr_rbf, X_test, Y_test)\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Kernel : Poly')\n",
    "svr_poly = train(svr_poly,X_train,Y_train)\n",
    "print_metrics(svr_poly, X_test, Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(svr_linear, open('Models/SVR (Linear)', 'wb'))\n",
    "\n",
    "\n",
    "#save model\n",
    "pickle.dump(svr_poly, open('Models/SVR (poly)', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, SVR with kernel as linear seems to work better than rbf kernel and poly kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error :  1.9807459017032563\n",
      "Root Mean Square Error :  1.4073897476190653\n",
      "Mean Absolute Error :  3.6865421895724935\n",
      "R2 Score :  0.5758089618179321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "treeRegressor = DecisionTreeRegressor(criterion='friedman_mse', max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "#training\n",
    "treeRegressor = train(treeRegressor, X_train, Y_train)\n",
    "\n",
    "#print metrics\n",
    "print_metrics(treeRegressor, X_test, Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(treeRegressor, open('Models/Decision Tree Regressor', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Till now, best model that worked here is Decision Tree Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error :  1.5802489958334118\n",
      "Root Mean Square Error :  1.2570795503202699\n",
      "Mean Absolute Error :  3.529004329004329\n",
      "R2 Score :  0.4116568905633121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forestRegressor = RandomForestRegressor(criterion='mae', max_depth=8, n_estimators=7, random_state=0)\n",
    "\n",
    "#training \n",
    "forestRegressor = train(forestRegressor, X_train, Y_train.flatten())\n",
    "\n",
    "#print metrics\n",
    "print_metrics(forestRegressor, X_test, Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(forestRegressor, open('Models/Random Forest Regressor', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest Regressor is betten than SVR and other linear models but works slightly worse than Decision tree regressor may be due to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error :  1.7050807758649544\n",
      "Root Mean Square Error :  1.3057874160310148\n",
      "Mean Absolute Error :  3.526882915381562\n",
      "R2 Score :  0.4101752509438138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor \n",
    "\n",
    "nnRegressor = MLPRegressor(hidden_layer_sizes=(20,10,4), #hidden layers\n",
    "                           activation='relu',#activation function after each layer\n",
    "                           learning_rate_init = 0.01,    #learning rate for optimization\n",
    "                           max_iter=500,            #number of iteration for training loop\n",
    "                           random_state=0)\n",
    "\n",
    "#training \n",
    "nnRegressor = train(nnRegressor, X_train, Y_train.flatten())\n",
    "\n",
    "#print metrics\n",
    "print_metrics(nnRegressor, X_test, Y_test)\n",
    "\n",
    "#save model\n",
    "pickle.dump(nnRegressor, open('Models/Neural Network', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network is also betten than SVR and linear models but works slightly worse than Random forest regressor and Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The given list of models worked differently, the order of their performance is given below (top-to-bottom is high-to-low)\n",
    "\n",
    "<ol>\n",
    "    <li> Decision Tree Regressor </li> <br>\n",
    "    <li> Random Forest Regressor </li> <br>\n",
    "    <li> Neural Network </li> <br>\n",
    "    <li> SVR (Linear) </li> <br>\n",
    "    <li> SVR (Poly) </li> <br>\n",
    "    <li> Ridge </li> <br>\n",
    "    <li> Linear Model </li> <br>\n",
    "    <li> Lasso </li> <br>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
